{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skdaS3SmZmOQ",
        "outputId": "11162408-2361-4e7f-b4d9-5e598d90ad7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 32.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 57.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 55.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2neyHonZrv-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"mixed_domain_godamit.csv\",usecols=[\"data\",\"label\"])\n",
        "df1=pd.read_csv(\"covid_kd_val.csv\",usecols=[\"data\",\"label\"])\n",
        "df2=pd.read_csv(\"covid_kd_test.csv\",usecols=[\"data\",\"label\"])\n",
        "df=df.sample(frac=1)\n",
        "df=df.reset_index()\n",
        "df.drop(\"index\",axis=1,inplace=True)\n",
        "df1=df1.sample(frac=1)\n",
        "df1=df1.reset_index()\n",
        "df1.drop(\"index\",axis=1,inplace=True)\n",
        "df2=df2.sample(frac=1)\n",
        "df2=df2.reset_index()\n",
        "df2.drop(\"index\",axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "06cvs1YJnSd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_text_cov=df1.loc[:,\"data\"].values\n",
        "val_labels_cov=df1.loc[:,\"label\"].values\n",
        "test_text_cov=df2.loc[:,\"data\"].values\n",
        "test_labels_cov=df2.loc[:,\"label\"].values\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df.loc[:int(0.7*df.shape[0]),'data'],df.loc[:int(0.7*df.shape[0]):,'label'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.3, \n",
        "                                                                    stratify=df.loc[:0.7*int(df.shape[0]),'label'])\n"
      ],
      "metadata": {
        "id": "HrrqIMZGc0ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187,
          "referenced_widgets": [
            "377a385f0a4f48468d3efd076632488a",
            "607837d06af8491ba41c95bebada7f3e",
            "ce3dbb3d27e04a368e9b77f500e2fbff",
            "a516e2e76bf14b6f9b3e6cd29ebc4bf8",
            "d3b8bcb5955d4668b562f632798e2c4e",
            "9f3096314e154489ad10e6a7af99dd9b",
            "3be3275f031b44048f8ab7683f4daf58",
            "bd2ed81f628c48a0b9f576c2010478cf",
            "f8e1d58c21c44c4684ffc4bf07d461c1",
            "2a83599918bd46b9b08cd8378f8d747e",
            "b85c25eaa74249e9abc59a5f1545b70d",
            "ff45c1862d1745e592337fcca7b5f7e5",
            "9f734704293e4742815b65bf71b7738b",
            "555c697177934416846db6e6a91bbac9",
            "be8749eda975498784ab51e0c3105c1b",
            "87de31a2e79e48868aadb61328321ed1",
            "0ab33c44b5874479b3f3e3035ad564a9",
            "17a695e410294d50b6ade6786deaa3a0",
            "e4d3fa2144584275b8c460d7d38ee968",
            "d95e5edb01664c08890640e566d736b9",
            "d91a324b339844b58f40ef82ec33a2b1",
            "7c013418de0d46eab81d70c4494d0063",
            "bf307d91be384de2bdc9cabe8e933360",
            "26ee9c4c1e7c42ee979603241fc84177",
            "6bf4279923fb4da28e27709a0a9dfe90",
            "4f8237bbfc9d4999bc10c9ca5c0395f9",
            "7dc78ecc1502408fbafdac5be8d90cdf",
            "e03132cdaa30424aa884d3d8078a6e8d",
            "5fe5fa64a07346c08d544ea62f169e48",
            "bd1cbfdc2bea4a84af73cab950cde7ff",
            "9982cdb421594ca7ae7454726b2a6565",
            "fbb7907e95264c48bc5e2f6d11667f50",
            "ca7c04ce17fe431d8d8de5681edf0e80"
          ]
        },
        "id": "3uTZF0RNaI4E",
        "outputId": "d81e4d8e-df4d-4060-d0e3-5cc6a1fee9e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/421 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "377a385f0a4f48468d3efd076632488a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff45c1862d1745e592337fcca7b5f7e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at digitalepidemiologylab/covid-twitter-bert were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf307d91be384de2bdc9cabe8e933360"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name='digitalepidemiologylab/covid-twitter-bert'\n",
        "bert = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6zJQ-c1an9e",
        "outputId": "a9e59332-14bc-46bc-8da9-f2191fd6e08f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "max_seq_len = 10\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDrdxJCVaqpL",
        "outputId": "b4d87dd8-4239-43d4-fdee-d1b8ab5113c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text_cov.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4xByk0maswj",
        "outputId": "a0fe9a8c-7c9a-43aa-b4d2-c28c0bdaacd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text_cov.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxVuEtcAawlT"
      },
      "outputs": [],
      "source": [
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vndlCl52azF0"
      },
      "outputs": [],
      "source": [
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels_cov.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZELFHj3a1Q8"
      },
      "outputs": [],
      "source": [
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels_cov.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elTPruaoa3TE"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 12\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBONzhoQa5Ra"
      },
      "outputs": [],
      "source": [
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dOu-cP1a7ID"
      },
      "outputs": [],
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "    def __init__(self, bert):\n",
        "      super(BERT_Arch, self).__init__()\n",
        "      self.bert = bert \n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      self.relu =  nn.ReLU()\n",
        "      self.fc1 = nn.Linear(1024,32)\n",
        "      self.fc2 = nn.Linear(32,2)\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "    def forward(self, sent_id, mask): \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "      x = self.fc1(cls_hs)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc2(x)\n",
        "      x = self.softmax(x)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t02muVGWa75D"
      },
      "outputs": [],
      "source": [
        "model = BERT_Arch(bert)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS63l8Hza-Kb",
        "outputId": "f6b06ad7-9a80-436a-a609-d398b1d8362a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNop0io6bBID",
        "outputId": "25b6e0ed-8dfa-4fb5-af75-559c2bc8273e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9862364765379937, 1.0141531169771576]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(train_labels),\n",
        "                                        y = train_labels                                                    \n",
        "                                    )\n",
        "class_weights = dict(zip(np.unique(train_labels), class_weights))\n",
        "\n",
        "li=[]\n",
        "li.append(class_weights[0])\n",
        "li.append(class_weights[1])\n",
        "print(li)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vWBX4JdbC8j"
      },
      "outputs": [],
      "source": [
        "weights= torch.tensor(li,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpvrG03dbFFr"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "  model.train()\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  total_preds=[]\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "    batch = [r.to(device) for r in batch]\n",
        "    sent_id, mask, labels = batch\n",
        "    model.zero_grad()        \n",
        "    preds = model(sent_id, mask)\n",
        "    loss = cross_entropy(preds, labels)\n",
        "    total_loss = total_loss + loss.item()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "    total_preds.append(preds)\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "  return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnHsHSVIbIFC"
      },
      "outputs": [],
      "source": [
        "def evaluate():\n",
        "  print(\"\\nEvaluating...\")\n",
        "  model.eval()\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  total_preds = []\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "    batch = [t.to(device) for t in batch]\n",
        "    sent_id, mask, labels = batch\n",
        "    with torch.no_grad():\n",
        "      preds = model(sent_id, mask)\n",
        "      loss = cross_entropy(preds,labels)\n",
        "      total_loss = total_loss + loss.item()\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "      total_preds.append(preds)\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "  return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ky_QIWrEbLND",
        "outputId": "2775915f-b403-4512-bb03-748b1f85f500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "  Batch    50  of  2,568.\n",
            "  Batch   100  of  2,568.\n",
            "  Batch   150  of  2,568.\n",
            "  Batch   200  of  2,568.\n",
            "  Batch   250  of  2,568.\n",
            "  Batch   300  of  2,568.\n",
            "  Batch   350  of  2,568.\n",
            "  Batch   400  of  2,568.\n",
            "  Batch   450  of  2,568.\n",
            "  Batch   500  of  2,568.\n",
            "  Batch   550  of  2,568.\n",
            "  Batch   600  of  2,568.\n",
            "  Batch   650  of  2,568.\n",
            "  Batch   700  of  2,568.\n",
            "  Batch   750  of  2,568.\n",
            "  Batch   800  of  2,568.\n",
            "  Batch   850  of  2,568.\n",
            "  Batch   900  of  2,568.\n",
            "  Batch   950  of  2,568.\n",
            "  Batch 1,000  of  2,568.\n",
            "  Batch 1,050  of  2,568.\n",
            "  Batch 1,100  of  2,568.\n",
            "  Batch 1,150  of  2,568.\n",
            "  Batch 1,200  of  2,568.\n",
            "  Batch 1,250  of  2,568.\n",
            "  Batch 1,300  of  2,568.\n",
            "  Batch 1,350  of  2,568.\n",
            "  Batch 1,400  of  2,568.\n",
            "  Batch 1,450  of  2,568.\n",
            "  Batch 1,500  of  2,568.\n",
            "  Batch 1,550  of  2,568.\n",
            "  Batch 1,600  of  2,568.\n",
            "  Batch 1,650  of  2,568.\n",
            "  Batch 1,700  of  2,568.\n",
            "  Batch 1,750  of  2,568.\n",
            "  Batch 1,800  of  2,568.\n",
            "  Batch 1,850  of  2,568.\n",
            "  Batch 1,900  of  2,568.\n",
            "  Batch 1,950  of  2,568.\n",
            "  Batch 2,000  of  2,568.\n",
            "  Batch 2,050  of  2,568.\n",
            "  Batch 2,100  of  2,568.\n",
            "  Batch 2,150  of  2,568.\n",
            "  Batch 2,200  of  2,568.\n",
            "  Batch 2,250  of  2,568.\n",
            "  Batch 2,300  of  2,568.\n",
            "  Batch 2,350  of  2,568.\n",
            "  Batch 2,400  of  2,568.\n",
            "  Batch 2,450  of  2,568.\n",
            "  Batch 2,500  of  2,568.\n",
            "  Batch 2,550  of  2,568.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of  1,462.\n",
            "  Batch   100  of  1,462.\n",
            "  Batch   150  of  1,462.\n",
            "  Batch   200  of  1,462.\n",
            "  Batch   250  of  1,462.\n",
            "  Batch   300  of  1,462.\n",
            "  Batch   350  of  1,462.\n",
            "  Batch   400  of  1,462.\n",
            "  Batch   450  of  1,462.\n",
            "  Batch   500  of  1,462.\n",
            "  Batch   550  of  1,462.\n",
            "  Batch   600  of  1,462.\n",
            "  Batch   650  of  1,462.\n",
            "  Batch   700  of  1,462.\n",
            "  Batch   750  of  1,462.\n",
            "  Batch   800  of  1,462.\n",
            "  Batch   850  of  1,462.\n",
            "  Batch   900  of  1,462.\n",
            "  Batch   950  of  1,462.\n",
            "  Batch 1,000  of  1,462.\n",
            "  Batch 1,050  of  1,462.\n",
            "  Batch 1,100  of  1,462.\n",
            "  Batch 1,150  of  1,462.\n",
            "  Batch 1,200  of  1,462.\n",
            "  Batch 1,250  of  1,462.\n",
            "  Batch 1,300  of  1,462.\n",
            "  Batch 1,350  of  1,462.\n",
            "  Batch 1,400  of  1,462.\n",
            "  Batch 1,450  of  1,462.\n",
            "\n",
            "Training Loss: 0.577\n",
            "Validation Loss: 0.790\n",
            "\n",
            " Epoch 2 / 10\n",
            "  Batch    50  of  2,568.\n",
            "  Batch   100  of  2,568.\n",
            "  Batch   150  of  2,568.\n",
            "  Batch   200  of  2,568.\n",
            "  Batch   250  of  2,568.\n",
            "  Batch   300  of  2,568.\n",
            "  Batch   350  of  2,568.\n",
            "  Batch   400  of  2,568.\n",
            "  Batch   450  of  2,568.\n",
            "  Batch   500  of  2,568.\n",
            "  Batch   550  of  2,568.\n",
            "  Batch   600  of  2,568.\n",
            "  Batch   650  of  2,568.\n",
            "  Batch   700  of  2,568.\n",
            "  Batch   750  of  2,568.\n",
            "  Batch   800  of  2,568.\n",
            "  Batch   850  of  2,568.\n",
            "  Batch   900  of  2,568.\n",
            "  Batch   950  of  2,568.\n",
            "  Batch 1,000  of  2,568.\n",
            "  Batch 1,050  of  2,568.\n",
            "  Batch 1,100  of  2,568.\n",
            "  Batch 1,150  of  2,568.\n",
            "  Batch 1,200  of  2,568.\n",
            "  Batch 1,250  of  2,568.\n",
            "  Batch 1,300  of  2,568.\n",
            "  Batch 1,350  of  2,568.\n",
            "  Batch 1,400  of  2,568.\n",
            "  Batch 1,450  of  2,568.\n",
            "  Batch 1,500  of  2,568.\n",
            "  Batch 1,550  of  2,568.\n",
            "  Batch 1,600  of  2,568.\n",
            "  Batch 1,650  of  2,568.\n",
            "  Batch 1,700  of  2,568.\n",
            "  Batch 1,750  of  2,568.\n",
            "  Batch 1,800  of  2,568.\n",
            "  Batch 1,850  of  2,568.\n",
            "  Batch 1,900  of  2,568.\n",
            "  Batch 1,950  of  2,568.\n",
            "  Batch 2,000  of  2,568.\n",
            "  Batch 2,050  of  2,568.\n",
            "  Batch 2,100  of  2,568.\n",
            "  Batch 2,150  of  2,568.\n",
            "  Batch 2,200  of  2,568.\n",
            "  Batch 2,250  of  2,568.\n",
            "  Batch 2,300  of  2,568.\n",
            "  Batch 2,350  of  2,568.\n",
            "  Batch 2,400  of  2,568.\n",
            "  Batch 2,450  of  2,568.\n",
            "  Batch 2,500  of  2,568.\n",
            "  Batch 2,550  of  2,568.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of  1,462.\n",
            "  Batch   100  of  1,462.\n",
            "  Batch   150  of  1,462.\n",
            "  Batch   200  of  1,462.\n",
            "  Batch   250  of  1,462.\n",
            "  Batch   300  of  1,462.\n",
            "  Batch   350  of  1,462.\n",
            "  Batch   400  of  1,462.\n",
            "  Batch   450  of  1,462.\n",
            "  Batch   500  of  1,462.\n",
            "  Batch   550  of  1,462.\n",
            "  Batch   600  of  1,462.\n",
            "  Batch   650  of  1,462.\n",
            "  Batch   700  of  1,462.\n",
            "  Batch   750  of  1,462.\n",
            "  Batch   800  of  1,462.\n",
            "  Batch   850  of  1,462.\n",
            "  Batch   900  of  1,462.\n",
            "  Batch   950  of  1,462.\n",
            "  Batch 1,000  of  1,462.\n",
            "  Batch 1,050  of  1,462.\n",
            "  Batch 1,100  of  1,462.\n",
            "  Batch 1,150  of  1,462.\n",
            "  Batch 1,200  of  1,462.\n",
            "  Batch 1,250  of  1,462.\n",
            "  Batch 1,300  of  1,462.\n",
            "  Batch 1,350  of  1,462.\n",
            "  Batch 1,400  of  1,462.\n",
            "  Batch 1,450  of  1,462.\n",
            "\n",
            "Training Loss: 0.540\n",
            "Validation Loss: 0.839\n",
            "\n",
            " Epoch 3 / 10\n",
            "  Batch    50  of  2,568.\n",
            "  Batch   100  of  2,568.\n",
            "  Batch   150  of  2,568.\n",
            "  Batch   200  of  2,568.\n",
            "  Batch   250  of  2,568.\n",
            "  Batch   300  of  2,568.\n",
            "  Batch   350  of  2,568.\n",
            "  Batch   400  of  2,568.\n",
            "  Batch   450  of  2,568.\n",
            "  Batch   500  of  2,568.\n",
            "  Batch   550  of  2,568.\n",
            "  Batch   600  of  2,568.\n",
            "  Batch   650  of  2,568.\n",
            "  Batch   700  of  2,568.\n",
            "  Batch   750  of  2,568.\n",
            "  Batch   800  of  2,568.\n",
            "  Batch   850  of  2,568.\n",
            "  Batch   900  of  2,568.\n",
            "  Batch   950  of  2,568.\n",
            "  Batch 1,000  of  2,568.\n",
            "  Batch 1,050  of  2,568.\n",
            "  Batch 1,100  of  2,568.\n",
            "  Batch 1,150  of  2,568.\n",
            "  Batch 1,200  of  2,568.\n",
            "  Batch 1,250  of  2,568.\n",
            "  Batch 1,300  of  2,568.\n",
            "  Batch 1,350  of  2,568.\n",
            "  Batch 1,400  of  2,568.\n",
            "  Batch 1,450  of  2,568.\n",
            "  Batch 1,500  of  2,568.\n",
            "  Batch 1,550  of  2,568.\n",
            "  Batch 1,600  of  2,568.\n",
            "  Batch 1,650  of  2,568.\n",
            "  Batch 1,700  of  2,568.\n",
            "  Batch 1,750  of  2,568.\n",
            "  Batch 1,800  of  2,568.\n",
            "  Batch 1,850  of  2,568.\n",
            "  Batch 1,900  of  2,568.\n",
            "  Batch 1,950  of  2,568.\n",
            "  Batch 2,000  of  2,568.\n",
            "  Batch 2,050  of  2,568.\n",
            "  Batch 2,100  of  2,568.\n",
            "  Batch 2,150  of  2,568.\n",
            "  Batch 2,200  of  2,568.\n",
            "  Batch 2,250  of  2,568.\n",
            "  Batch 2,300  of  2,568.\n",
            "  Batch 2,350  of  2,568.\n",
            "  Batch 2,400  of  2,568.\n",
            "  Batch 2,450  of  2,568.\n",
            "  Batch 2,500  of  2,568.\n",
            "  Batch 2,550  of  2,568.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of  1,462.\n",
            "  Batch   100  of  1,462.\n",
            "  Batch   150  of  1,462.\n",
            "  Batch   200  of  1,462.\n",
            "  Batch   250  of  1,462.\n",
            "  Batch   300  of  1,462.\n",
            "  Batch   350  of  1,462.\n",
            "  Batch   400  of  1,462.\n",
            "  Batch   450  of  1,462.\n",
            "  Batch   500  of  1,462.\n",
            "  Batch   550  of  1,462.\n",
            "  Batch   600  of  1,462.\n",
            "  Batch   650  of  1,462.\n",
            "  Batch   700  of  1,462.\n",
            "  Batch   750  of  1,462.\n",
            "  Batch   800  of  1,462.\n",
            "  Batch   850  of  1,462.\n",
            "  Batch   900  of  1,462.\n",
            "  Batch   950  of  1,462.\n",
            "  Batch 1,000  of  1,462.\n",
            "  Batch 1,050  of  1,462.\n",
            "  Batch 1,100  of  1,462.\n",
            "  Batch 1,150  of  1,462.\n",
            "  Batch 1,200  of  1,462.\n",
            "  Batch 1,250  of  1,462.\n",
            "  Batch 1,300  of  1,462.\n",
            "  Batch 1,350  of  1,462.\n",
            "  Batch 1,400  of  1,462.\n",
            "  Batch 1,450  of  1,462.\n",
            "\n",
            "Training Loss: 0.533\n",
            "Validation Loss: 0.829\n",
            "\n",
            " Epoch 4 / 10\n",
            "  Batch    50  of  2,568.\n",
            "  Batch   100  of  2,568.\n",
            "  Batch   150  of  2,568.\n",
            "  Batch   200  of  2,568.\n",
            "  Batch   250  of  2,568.\n",
            "  Batch   300  of  2,568.\n",
            "  Batch   350  of  2,568.\n",
            "  Batch   400  of  2,568.\n",
            "  Batch   450  of  2,568.\n",
            "  Batch   500  of  2,568.\n",
            "  Batch   550  of  2,568.\n",
            "  Batch   600  of  2,568.\n",
            "  Batch   650  of  2,568.\n",
            "  Batch   700  of  2,568.\n",
            "  Batch   750  of  2,568.\n",
            "  Batch   800  of  2,568.\n",
            "  Batch   850  of  2,568.\n",
            "  Batch   900  of  2,568.\n",
            "  Batch   950  of  2,568.\n",
            "  Batch 1,000  of  2,568.\n",
            "  Batch 1,050  of  2,568.\n",
            "  Batch 1,100  of  2,568.\n",
            "  Batch 1,150  of  2,568.\n",
            "  Batch 1,200  of  2,568.\n",
            "  Batch 1,250  of  2,568.\n",
            "  Batch 1,300  of  2,568.\n",
            "  Batch 1,350  of  2,568.\n",
            "  Batch 1,400  of  2,568.\n",
            "  Batch 1,450  of  2,568.\n",
            "  Batch 1,500  of  2,568.\n",
            "  Batch 1,550  of  2,568.\n",
            "  Batch 1,600  of  2,568.\n",
            "  Batch 1,650  of  2,568.\n",
            "  Batch 1,700  of  2,568.\n",
            "  Batch 1,750  of  2,568.\n",
            "  Batch 1,800  of  2,568.\n",
            "  Batch 1,850  of  2,568.\n",
            "  Batch 1,900  of  2,568.\n",
            "  Batch 1,950  of  2,568.\n",
            "  Batch 2,000  of  2,568.\n",
            "  Batch 2,050  of  2,568.\n",
            "  Batch 2,100  of  2,568.\n",
            "  Batch 2,150  of  2,568.\n",
            "  Batch 2,200  of  2,568.\n",
            "  Batch 2,250  of  2,568.\n",
            "  Batch 2,300  of  2,568.\n",
            "  Batch 2,350  of  2,568.\n",
            "  Batch 2,400  of  2,568.\n",
            "  Batch 2,450  of  2,568.\n",
            "  Batch 2,500  of  2,568.\n",
            "  Batch 2,550  of  2,568.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of  1,462.\n",
            "  Batch   100  of  1,462.\n",
            "  Batch   150  of  1,462.\n",
            "  Batch   200  of  1,462.\n",
            "  Batch   250  of  1,462.\n",
            "  Batch   300  of  1,462.\n",
            "  Batch   350  of  1,462.\n",
            "  Batch   400  of  1,462.\n",
            "  Batch   450  of  1,462.\n",
            "  Batch   500  of  1,462.\n",
            "  Batch   550  of  1,462.\n",
            "  Batch   600  of  1,462.\n",
            "  Batch   650  of  1,462.\n",
            "  Batch   700  of  1,462.\n",
            "  Batch   750  of  1,462.\n",
            "  Batch   800  of  1,462.\n",
            "  Batch   850  of  1,462.\n",
            "  Batch   900  of  1,462.\n",
            "  Batch   950  of  1,462.\n",
            "  Batch 1,000  of  1,462.\n",
            "  Batch 1,050  of  1,462.\n",
            "  Batch 1,100  of  1,462.\n",
            "  Batch 1,150  of  1,462.\n",
            "  Batch 1,200  of  1,462.\n",
            "  Batch 1,250  of  1,462.\n",
            "  Batch 1,300  of  1,462.\n",
            "  Batch 1,350  of  1,462.\n",
            "  Batch 1,400  of  1,462.\n",
            "  Batch 1,450  of  1,462.\n",
            "\n",
            "Training Loss: 0.527\n",
            "Validation Loss: 0.765\n",
            "\n",
            " Epoch 5 / 10\n",
            "  Batch    50  of  2,568.\n",
            "  Batch   100  of  2,568.\n",
            "  Batch   150  of  2,568.\n",
            "  Batch   200  of  2,568.\n",
            "  Batch   250  of  2,568.\n",
            "  Batch   300  of  2,568.\n",
            "  Batch   350  of  2,568.\n",
            "  Batch   400  of  2,568.\n",
            "  Batch   450  of  2,568.\n",
            "  Batch   500  of  2,568.\n",
            "  Batch   550  of  2,568.\n",
            "  Batch   600  of  2,568.\n",
            "  Batch   650  of  2,568.\n",
            "  Batch   700  of  2,568.\n",
            "  Batch   750  of  2,568.\n",
            "  Batch   800  of  2,568.\n",
            "  Batch   850  of  2,568.\n",
            "  Batch   900  of  2,568.\n",
            "  Batch   950  of  2,568.\n",
            "  Batch 1,000  of  2,568.\n",
            "  Batch 1,050  of  2,568.\n",
            "  Batch 1,100  of  2,568.\n",
            "  Batch 1,150  of  2,568.\n",
            "  Batch 1,200  of  2,568.\n",
            "  Batch 1,250  of  2,568.\n",
            "  Batch 1,300  of  2,568.\n",
            "  Batch 1,350  of  2,568.\n",
            "  Batch 1,400  of  2,568.\n",
            "  Batch 1,450  of  2,568.\n",
            "  Batch 1,500  of  2,568.\n",
            "  Batch 1,550  of  2,568.\n",
            "  Batch 1,600  of  2,568.\n",
            "  Batch 1,650  of  2,568.\n",
            "  Batch 1,700  of  2,568.\n",
            "  Batch 1,750  of  2,568.\n",
            "  Batch 1,800  of  2,568.\n",
            "  Batch 1,850  of  2,568.\n",
            "  Batch 1,900  of  2,568.\n",
            "  Batch 1,950  of  2,568.\n",
            "  Batch 2,000  of  2,568.\n",
            "  Batch 2,050  of  2,568.\n",
            "  Batch 2,100  of  2,568.\n",
            "  Batch 2,150  of  2,568.\n",
            "  Batch 2,200  of  2,568.\n",
            "  Batch 2,250  of  2,568.\n",
            "  Batch 2,300  of  2,568.\n",
            "  Batch 2,350  of  2,568.\n",
            "  Batch 2,400  of  2,568.\n",
            "  Batch 2,450  of  2,568.\n",
            "  Batch 2,500  of  2,568.\n",
            "  Batch 2,550  of  2,568.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of  1,462.\n",
            "  Batch   100  of  1,462.\n",
            "  Batch   150  of  1,462.\n",
            "  Batch   200  of  1,462.\n",
            "  Batch   250  of  1,462.\n",
            "  Batch   300  of  1,462.\n",
            "  Batch   350  of  1,462.\n",
            "  Batch   400  of  1,462.\n",
            "  Batch   450  of  1,462.\n",
            "  Batch   500  of  1,462.\n",
            "  Batch   550  of  1,462.\n",
            "  Batch   600  of  1,462.\n",
            "  Batch   650  of  1,462.\n",
            "  Batch   700  of  1,462.\n",
            "  Batch   750  of  1,462.\n",
            "  Batch   800  of  1,462.\n",
            "  Batch   850  of  1,462.\n",
            "  Batch   900  of  1,462.\n",
            "  Batch   950  of  1,462.\n",
            "  Batch 1,000  of  1,462.\n",
            "  Batch 1,050  of  1,462.\n",
            "  Batch 1,100  of  1,462.\n",
            "  Batch 1,150  of  1,462.\n",
            "  Batch 1,200  of  1,462.\n",
            "  Batch 1,250  of  1,462.\n",
            "  Batch 1,300  of  1,462.\n",
            "  Batch 1,350  of  1,462.\n",
            "  Batch 1,400  of  1,462.\n",
            "  Batch 1,450  of  1,462.\n",
            "\n",
            "Training Loss: 0.524\n",
            "Validation Loss: 0.895\n",
            "\n",
            " Epoch 6 / 10\n",
            "  Batch    50  of  2,568.\n",
            "  Batch   100  of  2,568.\n",
            "  Batch   150  of  2,568.\n",
            "  Batch   200  of  2,568.\n",
            "  Batch   250  of  2,568.\n",
            "  Batch   300  of  2,568.\n",
            "  Batch   350  of  2,568.\n",
            "  Batch   400  of  2,568.\n",
            "  Batch   450  of  2,568.\n",
            "  Batch   500  of  2,568.\n",
            "  Batch   550  of  2,568.\n",
            "  Batch   600  of  2,568.\n",
            "  Batch   650  of  2,568.\n",
            "  Batch   700  of  2,568.\n",
            "  Batch   750  of  2,568.\n",
            "  Batch   800  of  2,568.\n",
            "  Batch   850  of  2,568.\n",
            "  Batch   900  of  2,568.\n",
            "  Batch   950  of  2,568.\n",
            "  Batch 1,000  of  2,568.\n",
            "  Batch 1,050  of  2,568.\n",
            "  Batch 1,100  of  2,568.\n",
            "  Batch 1,150  of  2,568.\n",
            "  Batch 1,200  of  2,568.\n",
            "  Batch 1,250  of  2,568.\n",
            "  Batch 1,300  of  2,568.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-304f15ed8fee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-3236a6e339dd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# get model predictions for the current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# compute the loss between actual and predicted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-e54da7ab978a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0;31m#pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m         )\n\u001b[1;32m   1030\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m                 )\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         )\n\u001b[1;32m    538\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_full_backward_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "best_valid_loss = float('inf')\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "for epoch in range(epochs):\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    train_loss, _ = train()\n",
        "    valid_loss, _ = evaluate()\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlD2R3-KbORD",
        "outputId": "b12ea280-13e0-421f-c581-67860f862af6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = BERT_Arch(bert)\n",
        "model1 = model1.to(device)\n",
        "model1.load_state_dict(torch.load(path))\n",
        "model2= BERT_Arch(bert)\n",
        "model2= model2.to(device)\n",
        "model2.load_state_dict(torch.load(path))\n",
        "model3= BERT_Arch(bert)\n",
        "model3= model3.to(device)\n",
        "model3.load_state_dict(torch.load(path))\n",
        "model4= BERT_Arch(bert)\n",
        "model4= model4.to(device)\n",
        "model4.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvDNVQ5DccoV",
        "outputId": "2a2c9e59-59b1-49d9-a2ff-65f34fcbbf79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,25):\n",
        "  train_text_cov=df1.loc[:int(0.0416*i*0.6*df1.shape[0]),'data'].values\n",
        "  train_labels_cov=df1.loc[:int(0.0416*i*0.6*df1.shape[0]),'label'].values\n",
        "  val_text_cov=df1.loc[int(0.0416*i*0.6*df1.shape[0]):int(0.0416*i*0.8*df1.shape[0]),'data'].values\n",
        "  val_labels_cov=df1.loc[int(0.0416*i*0.6*df1.shape[0]):int(0.0416*i*0.8*df1.shape[0]),\"label\"].values\n",
        "  test_text_cov=df2.loc[int(0.0416*i*0.8*df2.shape[0]):,'data'].values\n",
        "  test_labels_cov=df2.loc[int(0.0416*i*0.8*df2.shape[0]):,'label'].values\n",
        "  max_seq_len = 10\n",
        "  tokens_train = tokenizer.batch_encode_plus(\n",
        "      train_text_cov.tolist(),\n",
        "      max_length = max_seq_len,\n",
        "      pad_to_max_length=True,\n",
        "      truncation=True,\n",
        "      return_token_type_ids=False\n",
        "  )\n",
        "  tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text_cov.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "  tokens_test = tokenizer.batch_encode_plus(\n",
        "      test_text_cov.tolist(),\n",
        "      max_length = max_seq_len,\n",
        "      pad_to_max_length=True,\n",
        "      truncation=True,\n",
        "      return_token_type_ids=False\n",
        "  )\n",
        "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "  train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "  train_y = torch.tensor(train_labels_cov.tolist())\n",
        "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "  val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "  val_y = torch.tensor(val_labels_cov.tolist())\n",
        "  test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "  test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "  test_y = torch.tensor(test_labels_cov.tolist())\n",
        "  batch_size = 1\n",
        "  train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "  val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "  val_sampler = SequentialSampler(val_data)\n",
        "  val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
        "  best_valid_loss = float('inf')\n",
        "  train_losses=[]\n",
        "  valid_losses=[]\n",
        "  epochs=3\n",
        "  for epoch in range(epochs):\n",
        "      print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "      train_loss, _ = train()\n",
        "      valid_loss, _ = evaluate()\n",
        "      if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model1.state_dict(), 'saved_weights1.pt')\n",
        "      train_losses.append(train_loss)\n",
        "      valid_losses.append(valid_loss)\n",
        "      print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "      print(f'Validation Loss: {valid_loss:.3f}')\n",
        "  path = 'saved_weights1.pt'\n",
        "  model1.load_state_dict(torch.load(path))\n",
        "  with torch.no_grad():\n",
        "    preds = model1(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "  preds = np.argmax(preds, axis = 1)\n",
        "  test_y = torch.tensor(test_labels_cov.tolist())\n",
        "  print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b3C4dRqXhz1u",
        "outputId": "1a31abd8-e4c6-4af1-b40a-db8896b774f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 3\n",
            "  Batch    50  of    438.\n",
            "  Batch   100  of    438.\n",
            "  Batch   150  of    438.\n",
            "  Batch   200  of    438.\n",
            "  Batch   250  of    438.\n",
            "  Batch   300  of    438.\n",
            "  Batch   350  of    438.\n",
            "  Batch   400  of    438.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    147.\n",
            "  Batch   100  of    147.\n",
            "\n",
            "Training Loss: 1.166\n",
            "Validation Loss: 1.309\n",
            "\n",
            " Epoch 2 / 3\n",
            "  Batch    50  of    438.\n",
            "  Batch   100  of    438.\n",
            "  Batch   150  of    438.\n",
            "  Batch   200  of    438.\n",
            "  Batch   250  of    438.\n",
            "  Batch   300  of    438.\n",
            "  Batch   350  of    438.\n",
            "  Batch   400  of    438.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    147.\n",
            "  Batch   100  of    147.\n",
            "\n",
            "Training Loss: 1.150\n",
            "Validation Loss: 1.278\n",
            "\n",
            " Epoch 3 / 3\n",
            "  Batch    50  of    438.\n",
            "  Batch   100  of    438.\n",
            "  Batch   150  of    438.\n",
            "  Batch   200  of    438.\n",
            "  Batch   250  of    438.\n",
            "  Batch   300  of    438.\n",
            "  Batch   350  of    438.\n",
            "  Batch   400  of    438.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    147.\n",
            "  Batch   100  of    147.\n",
            "\n",
            "Training Loss: 1.077\n",
            "Validation Loss: 1.475\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.54      0.55      3341\n",
            "           1       0.54      0.55      0.54      3253\n",
            "\n",
            "    accuracy                           0.55      6594\n",
            "   macro avg       0.55      0.55      0.55      6594\n",
            "weighted avg       0.55      0.55      0.55      6594\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 3\n",
            "  Batch    50  of    876.\n",
            "  Batch   100  of    876.\n",
            "  Batch   150  of    876.\n",
            "  Batch   200  of    876.\n",
            "  Batch   250  of    876.\n",
            "  Batch   300  of    876.\n",
            "  Batch   350  of    876.\n",
            "  Batch   400  of    876.\n",
            "  Batch   450  of    876.\n",
            "  Batch   500  of    876.\n",
            "  Batch   550  of    876.\n",
            "  Batch   600  of    876.\n",
            "  Batch   650  of    876.\n",
            "  Batch   700  of    876.\n",
            "  Batch   750  of    876.\n",
            "  Batch   800  of    876.\n",
            "  Batch   850  of    876.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    293.\n",
            "  Batch   100  of    293.\n",
            "  Batch   150  of    293.\n",
            "  Batch   200  of    293.\n",
            "  Batch   250  of    293.\n",
            "\n",
            "Training Loss: 0.909\n",
            "Validation Loss: 0.676\n",
            "\n",
            " Epoch 2 / 3\n",
            "  Batch    50  of    876.\n",
            "  Batch   100  of    876.\n",
            "  Batch   150  of    876.\n",
            "  Batch   200  of    876.\n",
            "  Batch   250  of    876.\n",
            "  Batch   300  of    876.\n",
            "  Batch   350  of    876.\n",
            "  Batch   400  of    876.\n",
            "  Batch   450  of    876.\n",
            "  Batch   500  of    876.\n",
            "  Batch   550  of    876.\n",
            "  Batch   600  of    876.\n",
            "  Batch   650  of    876.\n",
            "  Batch   700  of    876.\n",
            "  Batch   750  of    876.\n",
            "  Batch   800  of    876.\n",
            "  Batch   850  of    876.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    293.\n",
            "  Batch   100  of    293.\n",
            "  Batch   150  of    293.\n",
            "  Batch   200  of    293.\n",
            "  Batch   250  of    293.\n",
            "\n",
            "Training Loss: 0.870\n",
            "Validation Loss: 0.665\n",
            "\n",
            " Epoch 3 / 3\n",
            "  Batch    50  of    876.\n",
            "  Batch   100  of    876.\n",
            "  Batch   150  of    876.\n",
            "  Batch   200  of    876.\n",
            "  Batch   250  of    876.\n",
            "  Batch   300  of    876.\n",
            "  Batch   350  of    876.\n",
            "  Batch   400  of    876.\n",
            "  Batch   450  of    876.\n",
            "  Batch   500  of    876.\n",
            "  Batch   550  of    876.\n",
            "  Batch   600  of    876.\n",
            "  Batch   650  of    876.\n",
            "  Batch   700  of    876.\n",
            "  Batch   750  of    876.\n",
            "  Batch   800  of    876.\n",
            "  Batch   850  of    876.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    293.\n",
            "  Batch   100  of    293.\n",
            "  Batch   150  of    293.\n",
            "  Batch   200  of    293.\n",
            "  Batch   250  of    293.\n",
            "\n",
            "Training Loss: 0.761\n",
            "Validation Loss: 0.888\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.54      0.54      3222\n",
            "           1       0.54      0.55      0.54      3145\n",
            "\n",
            "    accuracy                           0.54      6367\n",
            "   macro avg       0.54      0.54      0.54      6367\n",
            "weighted avg       0.54      0.54      0.54      6367\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 3\n",
            "  Batch    50  of  1,314.\n",
            "  Batch   100  of  1,314.\n",
            "  Batch   150  of  1,314.\n",
            "  Batch   200  of  1,314.\n",
            "  Batch   250  of  1,314.\n",
            "  Batch   300  of  1,314.\n",
            "  Batch   350  of  1,314.\n",
            "  Batch   400  of  1,314.\n",
            "  Batch   450  of  1,314.\n",
            "  Batch   500  of  1,314.\n",
            "  Batch   550  of  1,314.\n",
            "  Batch   600  of  1,314.\n",
            "  Batch   650  of  1,314.\n",
            "  Batch   700  of  1,314.\n",
            "  Batch   750  of  1,314.\n",
            "  Batch   800  of  1,314.\n",
            "  Batch   850  of  1,314.\n",
            "  Batch   900  of  1,314.\n",
            "  Batch   950  of  1,314.\n",
            "  Batch 1,000  of  1,314.\n",
            "  Batch 1,050  of  1,314.\n",
            "  Batch 1,100  of  1,314.\n",
            "  Batch 1,150  of  1,314.\n",
            "  Batch 1,200  of  1,314.\n",
            "  Batch 1,250  of  1,314.\n",
            "  Batch 1,300  of  1,314.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    438.\n",
            "  Batch   100  of    438.\n",
            "  Batch   150  of    438.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-692d2f302092>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n Epoch {:} / {:}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m       \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_valid_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mbest_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-8a2bd80c0500>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0;31m# model predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m       \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0;31m# compute the validation loss between actual and predicted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-e54da7ab978a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0;31m#pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m         )\n\u001b[1;32m   1030\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m                 )\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         )\n\u001b[1;32m    538\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2,26,2):\n",
        "  train_text_cov=df1.loc[:int(0.0416*i*0.6*df1.shape[0]),'data'].values\n",
        "  train_labels_cov=df1.loc[:int(0.0416*i*0.6*df1.shape[0]),'label'].values\n",
        "  val_text_cov=df1.loc[int(0.0416*i*0.6*df1.shape[0]):int(0.0416*i*0.8*df1.shape[0]),'data'].values\n",
        "  val_labels_cov=df1.loc[int(0.0416*i*0.6*df1.shape[0]):int(0.0416*i*0.8*df1.shape[0]),\"label\"].values\n",
        "  test_text_cov=df2.loc[int(0.0416*i*0.8*df2.shape[0]):,'data'].values\n",
        "  test_labels_cov=df2.loc[int(0.0416*i*0.8*df2.shape[0]):,'label'].values\n",
        "  max_seq_len = 5\n",
        "  tokens_train = tokenizer.batch_encode_plus(\n",
        "      train_text_cov.tolist(),\n",
        "      max_length = max_seq_len,\n",
        "      pad_to_max_length=True,\n",
        "      truncation=True,\n",
        "      return_token_type_ids=False\n",
        "  )\n",
        "  tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text_cov.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "  tokens_test = tokenizer.batch_encode_plus(\n",
        "      test_text_cov.tolist(),\n",
        "      max_length = max_seq_len,\n",
        "      pad_to_max_length=True,\n",
        "      truncation=True,\n",
        "      return_token_type_ids=False\n",
        "  )\n",
        "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "  train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "  train_y = torch.tensor(train_labels_cov.tolist())\n",
        "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "  val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "  val_y = torch.tensor(val_labels_cov.tolist())\n",
        "  test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "  test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "  test_y = torch.tensor(test_labels_cov.tolist())\n",
        "  batch_size = 1\n",
        "  train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "  val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "  val_sampler = SequentialSampler(val_data)\n",
        "  val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
        "  best_valid_loss = float('inf')\n",
        "  train_losses=[]\n",
        "  valid_losses=[]\n",
        "  epochs=3\n",
        "  for epoch in range(epochs):\n",
        "      print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "      train_loss, _ = train()\n",
        "      valid_loss, _ = evaluate()\n",
        "      if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model2.state_dict(), 'saved_weights2.pt')\n",
        "      train_losses.append(train_loss)\n",
        "      valid_losses.append(valid_loss)\n",
        "      print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "      print(f'Validation Loss: {valid_loss:.3f}')\n",
        "  path = 'saved_weights2.pt'\n",
        "  model2.load_state_dict(torch.load(path))\n",
        "  with torch.no_grad():\n",
        "    preds = model2(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "  preds = np.argmax(preds, axis = 1)\n",
        "  test_y = torch.tensor(test_labels_cov.tolist())\n",
        "  print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8awvmwiw2kTN",
        "outputId": "e29f9bd6-af1d-46d7-9972-b810eb92f568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 3\n",
            "  Batch    50  of    876.\n",
            "  Batch   100  of    876.\n",
            "  Batch   150  of    876.\n",
            "  Batch   200  of    876.\n",
            "  Batch   250  of    876.\n",
            "  Batch   300  of    876.\n",
            "  Batch   350  of    876.\n",
            "  Batch   400  of    876.\n",
            "  Batch   450  of    876.\n",
            "  Batch   500  of    876.\n",
            "  Batch   550  of    876.\n",
            "  Batch   600  of    876.\n",
            "  Batch   650  of    876.\n",
            "  Batch   700  of    876.\n",
            "  Batch   750  of    876.\n",
            "  Batch   800  of    876.\n",
            "  Batch   850  of    876.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    293.\n",
            "  Batch   100  of    293.\n",
            "  Batch   150  of    293.\n",
            "  Batch   200  of    293.\n",
            "  Batch   250  of    293.\n",
            "\n",
            "Training Loss: 0.676\n",
            "Validation Loss: 0.650\n",
            "\n",
            " Epoch 2 / 3\n",
            "  Batch    50  of    876.\n",
            "  Batch   100  of    876.\n",
            "  Batch   150  of    876.\n",
            "  Batch   200  of    876.\n",
            "  Batch   250  of    876.\n",
            "  Batch   300  of    876.\n",
            "  Batch   350  of    876.\n",
            "  Batch   400  of    876.\n",
            "  Batch   450  of    876.\n",
            "  Batch   500  of    876.\n",
            "  Batch   550  of    876.\n",
            "  Batch   600  of    876.\n",
            "  Batch   650  of    876.\n",
            "  Batch   700  of    876.\n",
            "  Batch   750  of    876.\n",
            "  Batch   800  of    876.\n",
            "  Batch   850  of    876.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    293.\n",
            "  Batch   100  of    293.\n",
            "  Batch   150  of    293.\n",
            "  Batch   200  of    293.\n",
            "  Batch   250  of    293.\n",
            "\n",
            "Training Loss: 0.698\n",
            "Validation Loss: 0.690\n",
            "\n",
            " Epoch 3 / 3\n",
            "  Batch    50  of    876.\n",
            "  Batch   100  of    876.\n",
            "  Batch   150  of    876.\n",
            "  Batch   200  of    876.\n",
            "  Batch   250  of    876.\n",
            "  Batch   300  of    876.\n",
            "  Batch   350  of    876.\n",
            "  Batch   400  of    876.\n",
            "  Batch   450  of    876.\n",
            "  Batch   500  of    876.\n",
            "  Batch   550  of    876.\n",
            "  Batch   600  of    876.\n",
            "  Batch   650  of    876.\n",
            "  Batch   700  of    876.\n",
            "  Batch   750  of    876.\n",
            "  Batch   800  of    876.\n",
            "  Batch   850  of    876.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    293.\n",
            "  Batch   100  of    293.\n",
            "  Batch   150  of    293.\n",
            "  Batch   200  of    293.\n",
            "  Batch   250  of    293.\n",
            "\n",
            "Training Loss: 0.735\n",
            "Validation Loss: 0.654\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.44      0.49      3239\n",
            "           1       0.52      0.63      0.57      3128\n",
            "\n",
            "    accuracy                           0.53      6367\n",
            "   macro avg       0.53      0.53      0.53      6367\n",
            "weighted avg       0.53      0.53      0.53      6367\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 3\n",
            "  Batch    50  of  1,751.\n",
            "  Batch   100  of  1,751.\n",
            "  Batch   150  of  1,751.\n",
            "  Batch   200  of  1,751.\n",
            "  Batch   250  of  1,751.\n",
            "  Batch   300  of  1,751.\n",
            "  Batch   350  of  1,751.\n",
            "  Batch   400  of  1,751.\n",
            "  Batch   450  of  1,751.\n",
            "  Batch   500  of  1,751.\n",
            "  Batch   550  of  1,751.\n",
            "  Batch   600  of  1,751.\n",
            "  Batch   650  of  1,751.\n",
            "  Batch   700  of  1,751.\n",
            "  Batch   750  of  1,751.\n",
            "  Batch   800  of  1,751.\n",
            "  Batch   850  of  1,751.\n",
            "  Batch   900  of  1,751.\n",
            "  Batch   950  of  1,751.\n",
            "  Batch 1,000  of  1,751.\n",
            "  Batch 1,050  of  1,751.\n",
            "  Batch 1,100  of  1,751.\n",
            "  Batch 1,150  of  1,751.\n",
            "  Batch 1,200  of  1,751.\n",
            "  Batch 1,250  of  1,751.\n",
            "  Batch 1,300  of  1,751.\n",
            "  Batch 1,350  of  1,751.\n",
            "  Batch 1,400  of  1,751.\n",
            "  Batch 1,450  of  1,751.\n",
            "  Batch 1,500  of  1,751.\n",
            "  Batch 1,550  of  1,751.\n",
            "  Batch 1,600  of  1,751.\n",
            "  Batch 1,650  of  1,751.\n",
            "  Batch 1,700  of  1,751.\n",
            "  Batch 1,750  of  1,751.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    585.\n",
            "  Batch   100  of    585.\n",
            "  Batch   150  of    585.\n",
            "  Batch   200  of    585.\n",
            "  Batch   250  of    585.\n",
            "  Batch   300  of    585.\n",
            "  Batch   350  of    585.\n",
            "  Batch   400  of    585.\n",
            "  Batch   450  of    585.\n",
            "  Batch   500  of    585.\n",
            "  Batch   550  of    585.\n",
            "\n",
            "Training Loss: 0.716\n",
            "Validation Loss: 0.435\n",
            "\n",
            " Epoch 2 / 3\n",
            "  Batch    50  of  1,751.\n",
            "  Batch   100  of  1,751.\n",
            "  Batch   150  of  1,751.\n",
            "  Batch   200  of  1,751.\n",
            "  Batch   250  of  1,751.\n",
            "  Batch   300  of  1,751.\n",
            "  Batch   350  of  1,751.\n",
            "  Batch   400  of  1,751.\n",
            "  Batch   450  of  1,751.\n",
            "  Batch   500  of  1,751.\n",
            "  Batch   550  of  1,751.\n",
            "  Batch   600  of  1,751.\n",
            "  Batch   650  of  1,751.\n",
            "  Batch   700  of  1,751.\n",
            "  Batch   750  of  1,751.\n",
            "  Batch   800  of  1,751.\n",
            "  Batch   850  of  1,751.\n",
            "  Batch   900  of  1,751.\n",
            "  Batch   950  of  1,751.\n",
            "  Batch 1,000  of  1,751.\n",
            "  Batch 1,050  of  1,751.\n",
            "  Batch 1,100  of  1,751.\n",
            "  Batch 1,150  of  1,751.\n",
            "  Batch 1,200  of  1,751.\n",
            "  Batch 1,250  of  1,751.\n",
            "  Batch 1,300  of  1,751.\n",
            "  Batch 1,350  of  1,751.\n",
            "  Batch 1,400  of  1,751.\n",
            "  Batch 1,450  of  1,751.\n",
            "  Batch 1,500  of  1,751.\n",
            "  Batch 1,550  of  1,751.\n",
            "  Batch 1,600  of  1,751.\n",
            "  Batch 1,650  of  1,751.\n",
            "  Batch 1,700  of  1,751.\n",
            "  Batch 1,750  of  1,751.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    585.\n",
            "  Batch   100  of    585.\n",
            "  Batch   150  of    585.\n",
            "  Batch   200  of    585.\n",
            "  Batch   250  of    585.\n",
            "  Batch   300  of    585.\n",
            "  Batch   350  of    585.\n",
            "  Batch   400  of    585.\n",
            "  Batch   450  of    585.\n",
            "  Batch   500  of    585.\n",
            "  Batch   550  of    585.\n",
            "\n",
            "Training Loss: 0.684\n",
            "Validation Loss: 0.544\n",
            "\n",
            " Epoch 3 / 3\n",
            "  Batch    50  of  1,751.\n",
            "  Batch   100  of  1,751.\n",
            "  Batch   150  of  1,751.\n",
            "  Batch   200  of  1,751.\n",
            "  Batch   250  of  1,751.\n",
            "  Batch   300  of  1,751.\n",
            "  Batch   350  of  1,751.\n",
            "  Batch   400  of  1,751.\n",
            "  Batch   450  of  1,751.\n",
            "  Batch   500  of  1,751.\n",
            "  Batch   550  of  1,751.\n",
            "  Batch   600  of  1,751.\n",
            "  Batch   650  of  1,751.\n",
            "  Batch   700  of  1,751.\n",
            "  Batch   750  of  1,751.\n",
            "  Batch   800  of  1,751.\n",
            "  Batch   850  of  1,751.\n",
            "  Batch   900  of  1,751.\n",
            "  Batch   950  of  1,751.\n",
            "  Batch 1,000  of  1,751.\n",
            "  Batch 1,050  of  1,751.\n",
            "  Batch 1,100  of  1,751.\n",
            "  Batch 1,150  of  1,751.\n",
            "  Batch 1,200  of  1,751.\n",
            "  Batch 1,250  of  1,751.\n",
            "  Batch 1,300  of  1,751.\n",
            "  Batch 1,350  of  1,751.\n",
            "  Batch 1,400  of  1,751.\n",
            "  Batch 1,450  of  1,751.\n",
            "  Batch 1,500  of  1,751.\n",
            "  Batch 1,550  of  1,751.\n",
            "  Batch 1,600  of  1,751.\n",
            "  Batch 1,650  of  1,751.\n",
            "  Batch 1,700  of  1,751.\n",
            "  Batch 1,750  of  1,751.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    585.\n",
            "  Batch   100  of    585.\n",
            "  Batch   150  of    585.\n",
            "  Batch   200  of    585.\n",
            "  Batch   250  of    585.\n",
            "  Batch   300  of    585.\n",
            "  Batch   350  of    585.\n",
            "  Batch   400  of    585.\n",
            "  Batch   450  of    585.\n",
            "  Batch   500  of    585.\n",
            "  Batch   550  of    585.\n",
            "\n",
            "Training Loss: 0.661\n",
            "Validation Loss: 0.600\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.43      0.48      3019\n",
            "           1       0.51      0.62      0.56      2894\n",
            "\n",
            "    accuracy                           0.52      5913\n",
            "   macro avg       0.53      0.52      0.52      5913\n",
            "weighted avg       0.53      0.52      0.52      5913\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 3\n",
            "  Batch    50  of  2,627.\n",
            "  Batch   100  of  2,627.\n",
            "  Batch   150  of  2,627.\n",
            "  Batch   200  of  2,627.\n",
            "  Batch   250  of  2,627.\n",
            "  Batch   300  of  2,627.\n",
            "  Batch   350  of  2,627.\n",
            "  Batch   400  of  2,627.\n",
            "  Batch   450  of  2,627.\n",
            "  Batch   500  of  2,627.\n",
            "  Batch   550  of  2,627.\n",
            "  Batch   600  of  2,627.\n",
            "  Batch   650  of  2,627.\n",
            "  Batch   700  of  2,627.\n",
            "  Batch   750  of  2,627.\n",
            "  Batch   800  of  2,627.\n",
            "  Batch   850  of  2,627.\n",
            "  Batch   900  of  2,627.\n",
            "  Batch   950  of  2,627.\n",
            "  Batch 1,000  of  2,627.\n",
            "  Batch 1,050  of  2,627.\n",
            "  Batch 1,100  of  2,627.\n",
            "  Batch 1,150  of  2,627.\n",
            "  Batch 1,200  of  2,627.\n",
            "  Batch 1,250  of  2,627.\n",
            "  Batch 1,300  of  2,627.\n",
            "  Batch 1,350  of  2,627.\n",
            "  Batch 1,400  of  2,627.\n",
            "  Batch 1,450  of  2,627.\n",
            "  Batch 1,500  of  2,627.\n",
            "  Batch 1,550  of  2,627.\n",
            "  Batch 1,600  of  2,627.\n",
            "  Batch 1,650  of  2,627.\n",
            "  Batch 1,700  of  2,627.\n",
            "  Batch 1,750  of  2,627.\n",
            "  Batch 1,800  of  2,627.\n",
            "  Batch 1,850  of  2,627.\n",
            "  Batch 1,900  of  2,627.\n",
            "  Batch 1,950  of  2,627.\n",
            "  Batch 2,000  of  2,627.\n",
            "  Batch 2,050  of  2,627.\n",
            "  Batch 2,100  of  2,627.\n",
            "  Batch 2,150  of  2,627.\n",
            "  Batch 2,200  of  2,627.\n",
            "  Batch 2,250  of  2,627.\n",
            "  Batch 2,300  of  2,627.\n",
            "  Batch 2,350  of  2,627.\n",
            "  Batch 2,400  of  2,627.\n",
            "  Batch 2,450  of  2,627.\n",
            "  Batch 2,500  of  2,627.\n",
            "  Batch 2,550  of  2,627.\n",
            "  Batch 2,600  of  2,627.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    876.\n",
            "  Batch   100  of    876.\n",
            "  Batch   150  of    876.\n",
            "  Batch   200  of    876.\n",
            "  Batch   250  of    876.\n",
            "  Batch   300  of    876.\n",
            "  Batch   350  of    876.\n",
            "  Batch   400  of    876.\n",
            "  Batch   450  of    876.\n",
            "  Batch   500  of    876.\n",
            "  Batch   550  of    876.\n",
            "  Batch   600  of    876.\n",
            "  Batch   650  of    876.\n",
            "  Batch   700  of    876.\n",
            "  Batch   750  of    876.\n",
            "  Batch   800  of    876.\n",
            "  Batch   850  of    876.\n",
            "\n",
            "Training Loss: 0.689\n",
            "Validation Loss: 0.593\n",
            "\n",
            " Epoch 2 / 3\n",
            "  Batch    50  of  2,627.\n",
            "  Batch   100  of  2,627.\n",
            "  Batch   150  of  2,627.\n",
            "  Batch   200  of  2,627.\n",
            "  Batch   250  of  2,627.\n",
            "  Batch   300  of  2,627.\n",
            "  Batch   350  of  2,627.\n",
            "  Batch   400  of  2,627.\n",
            "  Batch   450  of  2,627.\n",
            "  Batch   500  of  2,627.\n",
            "  Batch   550  of  2,627.\n",
            "  Batch   600  of  2,627.\n",
            "  Batch   650  of  2,627.\n",
            "  Batch   700  of  2,627.\n",
            "  Batch   750  of  2,627.\n",
            "  Batch   800  of  2,627.\n",
            "  Batch   850  of  2,627.\n",
            "  Batch   900  of  2,627.\n",
            "  Batch   950  of  2,627.\n",
            "  Batch 1,000  of  2,627.\n",
            "  Batch 1,050  of  2,627.\n",
            "  Batch 1,100  of  2,627.\n",
            "  Batch 1,150  of  2,627.\n",
            "  Batch 1,200  of  2,627.\n",
            "  Batch 1,250  of  2,627.\n",
            "  Batch 1,300  of  2,627.\n",
            "  Batch 1,350  of  2,627.\n",
            "  Batch 1,400  of  2,627.\n",
            "  Batch 1,450  of  2,627.\n",
            "  Batch 1,500  of  2,627.\n",
            "  Batch 1,550  of  2,627.\n",
            "  Batch 1,600  of  2,627.\n",
            "  Batch 1,650  of  2,627.\n",
            "  Batch 1,700  of  2,627.\n",
            "  Batch 1,750  of  2,627.\n",
            "  Batch 1,800  of  2,627.\n",
            "  Batch 1,850  of  2,627.\n",
            "  Batch 1,900  of  2,627.\n",
            "  Batch 1,950  of  2,627.\n",
            "  Batch 2,000  of  2,627.\n",
            "  Batch 2,050  of  2,627.\n",
            "  Batch 2,100  of  2,627.\n",
            "  Batch 2,150  of  2,627.\n",
            "  Batch 2,200  of  2,627.\n",
            "  Batch 2,250  of  2,627.\n",
            "  Batch 2,300  of  2,627.\n",
            "  Batch 2,350  of  2,627.\n",
            "  Batch 2,400  of  2,627.\n",
            "  Batch 2,450  of  2,627.\n",
            "  Batch 2,500  of  2,627.\n",
            "  Batch 2,550  of  2,627.\n",
            "  Batch 2,600  of  2,627.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    876.\n",
            "  Batch   100  of    876.\n",
            "  Batch   150  of    876.\n",
            "  Batch   200  of    876.\n",
            "  Batch   250  of    876.\n",
            "  Batch   300  of    876.\n",
            "  Batch   350  of    876.\n",
            "  Batch   400  of    876.\n",
            "  Batch   450  of    876.\n",
            "  Batch   500  of    876.\n",
            "  Batch   550  of    876.\n",
            "  Batch   600  of    876.\n",
            "  Batch   650  of    876.\n",
            "  Batch   700  of    876.\n",
            "  Batch   750  of    876.\n",
            "  Batch   800  of    876.\n",
            "  Batch   850  of    876.\n",
            "\n",
            "Training Loss: 0.690\n",
            "Validation Loss: 0.673\n",
            "\n",
            " Epoch 3 / 3\n",
            "  Batch    50  of  2,627.\n",
            "  Batch   100  of  2,627.\n",
            "  Batch   150  of  2,627.\n",
            "  Batch   200  of  2,627.\n",
            "  Batch   250  of  2,627.\n",
            "  Batch   300  of  2,627.\n",
            "  Batch   350  of  2,627.\n",
            "  Batch   400  of  2,627.\n",
            "  Batch   450  of  2,627.\n",
            "  Batch   500  of  2,627.\n",
            "  Batch   550  of  2,627.\n",
            "  Batch   600  of  2,627.\n",
            "  Batch   650  of  2,627.\n",
            "  Batch   700  of  2,627.\n",
            "  Batch   750  of  2,627.\n",
            "  Batch   800  of  2,627.\n",
            "  Batch   850  of  2,627.\n",
            "  Batch   900  of  2,627.\n",
            "  Batch   950  of  2,627.\n",
            "  Batch 1,000  of  2,627.\n",
            "  Batch 1,050  of  2,627.\n",
            "  Batch 1,100  of  2,627.\n",
            "  Batch 1,150  of  2,627.\n",
            "  Batch 1,200  of  2,627.\n",
            "  Batch 1,250  of  2,627.\n",
            "  Batch 1,300  of  2,627.\n",
            "  Batch 1,350  of  2,627.\n",
            "  Batch 1,400  of  2,627.\n",
            "  Batch 1,450  of  2,627.\n",
            "  Batch 1,500  of  2,627.\n",
            "  Batch 1,550  of  2,627.\n",
            "  Batch 1,600  of  2,627.\n",
            "  Batch 1,650  of  2,627.\n",
            "  Batch 1,700  of  2,627.\n",
            "  Batch 1,750  of  2,627.\n",
            "  Batch 1,800  of  2,627.\n",
            "  Batch 1,850  of  2,627.\n",
            "  Batch 1,900  of  2,627.\n",
            "  Batch 1,950  of  2,627.\n",
            "  Batch 2,000  of  2,627.\n",
            "  Batch 2,050  of  2,627.\n",
            "  Batch 2,100  of  2,627.\n",
            "  Batch 2,150  of  2,627.\n",
            "  Batch 2,200  of  2,627.\n",
            "  Batch 2,250  of  2,627.\n",
            "  Batch 2,300  of  2,627.\n",
            "  Batch 2,350  of  2,627.\n",
            "  Batch 2,400  of  2,627.\n",
            "  Batch 2,450  of  2,627.\n",
            "  Batch 2,500  of  2,627.\n",
            "  Batch 2,550  of  2,627.\n",
            "  Batch 2,600  of  2,627.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    876.\n",
            "  Batch   100  of    876.\n",
            "  Batch   150  of    876.\n",
            "  Batch   200  of    876.\n",
            "  Batch   250  of    876.\n",
            "  Batch   300  of    876.\n",
            "  Batch   350  of    876.\n",
            "  Batch   400  of    876.\n",
            "  Batch   450  of    876.\n",
            "  Batch   500  of    876.\n",
            "  Batch   550  of    876.\n",
            "  Batch   600  of    876.\n",
            "  Batch   650  of    876.\n",
            "  Batch   700  of    876.\n",
            "  Batch   750  of    876.\n",
            "  Batch   800  of    876.\n",
            "  Batch   850  of    876.\n",
            "\n",
            "Training Loss: 0.700\n",
            "Validation Loss: 0.740\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.43      0.48      2796\n",
            "           1       0.50      0.61      0.55      2663\n",
            "\n",
            "    accuracy                           0.52      5459\n",
            "   macro avg       0.52      0.52      0.52      5459\n",
            "weighted avg       0.52      0.52      0.51      5459\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 3\n",
            "  Batch    50  of  3,502.\n",
            "  Batch   100  of  3,502.\n",
            "  Batch   150  of  3,502.\n",
            "  Batch   200  of  3,502.\n",
            "  Batch   250  of  3,502.\n",
            "  Batch   300  of  3,502.\n",
            "  Batch   350  of  3,502.\n",
            "  Batch   400  of  3,502.\n",
            "  Batch   450  of  3,502.\n",
            "  Batch   500  of  3,502.\n",
            "  Batch   550  of  3,502.\n",
            "  Batch   600  of  3,502.\n",
            "  Batch   650  of  3,502.\n",
            "  Batch   700  of  3,502.\n",
            "  Batch   750  of  3,502.\n",
            "  Batch   800  of  3,502.\n",
            "  Batch   850  of  3,502.\n",
            "  Batch   900  of  3,502.\n",
            "  Batch   950  of  3,502.\n",
            "  Batch 1,000  of  3,502.\n",
            "  Batch 1,050  of  3,502.\n",
            "  Batch 1,100  of  3,502.\n",
            "  Batch 1,150  of  3,502.\n",
            "  Batch 1,200  of  3,502.\n",
            "  Batch 1,250  of  3,502.\n",
            "  Batch 1,300  of  3,502.\n",
            "  Batch 1,350  of  3,502.\n",
            "  Batch 1,400  of  3,502.\n",
            "  Batch 1,450  of  3,502.\n",
            "  Batch 1,500  of  3,502.\n",
            "  Batch 1,550  of  3,502.\n",
            "  Batch 1,600  of  3,502.\n",
            "  Batch 1,650  of  3,502.\n",
            "  Batch 1,700  of  3,502.\n",
            "  Batch 1,750  of  3,502.\n",
            "  Batch 1,800  of  3,502.\n",
            "  Batch 1,850  of  3,502.\n",
            "  Batch 1,900  of  3,502.\n",
            "  Batch 1,950  of  3,502.\n",
            "  Batch 2,000  of  3,502.\n",
            "  Batch 2,050  of  3,502.\n",
            "  Batch 2,100  of  3,502.\n",
            "  Batch 2,150  of  3,502.\n",
            "  Batch 2,200  of  3,502.\n",
            "  Batch 2,250  of  3,502.\n",
            "  Batch 2,300  of  3,502.\n",
            "  Batch 2,350  of  3,502.\n",
            "  Batch 2,400  of  3,502.\n",
            "  Batch 2,450  of  3,502.\n",
            "  Batch 2,500  of  3,502.\n",
            "  Batch 2,550  of  3,502.\n",
            "  Batch 2,600  of  3,502.\n",
            "  Batch 2,650  of  3,502.\n",
            "  Batch 2,700  of  3,502.\n",
            "  Batch 2,750  of  3,502.\n",
            "  Batch 2,800  of  3,502.\n",
            "  Batch 2,850  of  3,502.\n",
            "  Batch 2,900  of  3,502.\n",
            "  Batch 2,950  of  3,502.\n",
            "  Batch 3,000  of  3,502.\n",
            "  Batch 3,050  of  3,502.\n",
            "  Batch 3,100  of  3,502.\n",
            "  Batch 3,150  of  3,502.\n",
            "  Batch 3,200  of  3,502.\n",
            "  Batch 3,250  of  3,502.\n",
            "  Batch 3,300  of  3,502.\n",
            "  Batch 3,350  of  3,502.\n",
            "  Batch 3,400  of  3,502.\n",
            "  Batch 3,450  of  3,502.\n",
            "  Batch 3,500  of  3,502.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of  1,168.\n",
            "  Batch   100  of  1,168.\n",
            "  Batch   150  of  1,168.\n",
            "  Batch   200  of  1,168.\n",
            "  Batch   250  of  1,168.\n",
            "  Batch   300  of  1,168.\n",
            "  Batch   350  of  1,168.\n",
            "  Batch   400  of  1,168.\n",
            "  Batch   450  of  1,168.\n",
            "  Batch   500  of  1,168.\n",
            "  Batch   550  of  1,168.\n",
            "  Batch   600  of  1,168.\n",
            "  Batch   650  of  1,168.\n",
            "  Batch   700  of  1,168.\n",
            "  Batch   750  of  1,168.\n",
            "  Batch   800  of  1,168.\n",
            "  Batch   850  of  1,168.\n",
            "  Batch   900  of  1,168.\n",
            "  Batch   950  of  1,168.\n",
            "  Batch 1,000  of  1,168.\n",
            "  Batch 1,050  of  1,168.\n",
            "  Batch 1,100  of  1,168.\n",
            "  Batch 1,150  of  1,168.\n",
            "\n",
            "Training Loss: 0.721\n",
            "Validation Loss: 0.467\n",
            "\n",
            " Epoch 2 / 3\n",
            "  Batch    50  of  3,502.\n",
            "  Batch   100  of  3,502.\n",
            "  Batch   150  of  3,502.\n",
            "  Batch   200  of  3,502.\n",
            "  Batch   250  of  3,502.\n",
            "  Batch   300  of  3,502.\n",
            "  Batch   350  of  3,502.\n",
            "  Batch   400  of  3,502.\n",
            "  Batch   450  of  3,502.\n",
            "  Batch   500  of  3,502.\n",
            "  Batch   550  of  3,502.\n",
            "  Batch   600  of  3,502.\n",
            "  Batch   650  of  3,502.\n",
            "  Batch   700  of  3,502.\n",
            "  Batch   750  of  3,502.\n",
            "  Batch   800  of  3,502.\n",
            "  Batch   850  of  3,502.\n",
            "  Batch   900  of  3,502.\n",
            "  Batch   950  of  3,502.\n",
            "  Batch 1,000  of  3,502.\n",
            "  Batch 1,050  of  3,502.\n",
            "  Batch 1,100  of  3,502.\n",
            "  Batch 1,150  of  3,502.\n",
            "  Batch 1,200  of  3,502.\n",
            "  Batch 1,250  of  3,502.\n",
            "  Batch 1,300  of  3,502.\n",
            "  Batch 1,350  of  3,502.\n",
            "  Batch 1,400  of  3,502.\n",
            "  Batch 1,450  of  3,502.\n",
            "  Batch 1,500  of  3,502.\n",
            "  Batch 1,550  of  3,502.\n",
            "  Batch 1,600  of  3,502.\n",
            "  Batch 1,650  of  3,502.\n",
            "  Batch 1,700  of  3,502.\n",
            "  Batch 1,750  of  3,502.\n",
            "  Batch 1,800  of  3,502.\n",
            "  Batch 1,850  of  3,502.\n",
            "  Batch 1,900  of  3,502.\n",
            "  Batch 1,950  of  3,502.\n",
            "  Batch 2,000  of  3,502.\n",
            "  Batch 2,050  of  3,502.\n",
            "  Batch 2,100  of  3,502.\n",
            "  Batch 2,150  of  3,502.\n",
            "  Batch 2,200  of  3,502.\n",
            "  Batch 2,250  of  3,502.\n",
            "  Batch 2,300  of  3,502.\n",
            "  Batch 2,350  of  3,502.\n",
            "  Batch 2,400  of  3,502.\n",
            "  Batch 2,450  of  3,502.\n",
            "  Batch 2,500  of  3,502.\n",
            "  Batch 2,550  of  3,502.\n",
            "  Batch 2,600  of  3,502.\n",
            "  Batch 2,650  of  3,502.\n",
            "  Batch 2,700  of  3,502.\n",
            "  Batch 2,750  of  3,502.\n",
            "  Batch 2,800  of  3,502.\n",
            "  Batch 2,850  of  3,502.\n",
            "  Batch 2,900  of  3,502.\n",
            "  Batch 2,950  of  3,502.\n",
            "  Batch 3,000  of  3,502.\n",
            "  Batch 3,050  of  3,502.\n",
            "  Batch 3,100  of  3,502.\n",
            "  Batch 3,150  of  3,502.\n",
            "  Batch 3,200  of  3,502.\n",
            "  Batch 3,250  of  3,502.\n",
            "  Batch 3,300  of  3,502.\n",
            "  Batch 3,350  of  3,502.\n",
            "  Batch 3,400  of  3,502.\n",
            "  Batch 3,450  of  3,502.\n",
            "  Batch 3,500  of  3,502.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of  1,168.\n",
            "  Batch   100  of  1,168.\n",
            "  Batch   150  of  1,168.\n",
            "  Batch   200  of  1,168.\n",
            "  Batch   250  of  1,168.\n",
            "  Batch   300  of  1,168.\n",
            "  Batch   350  of  1,168.\n",
            "  Batch   400  of  1,168.\n",
            "  Batch   450  of  1,168.\n",
            "  Batch   500  of  1,168.\n",
            "  Batch   550  of  1,168.\n",
            "  Batch   600  of  1,168.\n",
            "  Batch   650  of  1,168.\n",
            "  Batch   700  of  1,168.\n",
            "  Batch   750  of  1,168.\n",
            "  Batch   800  of  1,168.\n",
            "  Batch   850  of  1,168.\n",
            "  Batch   900  of  1,168.\n",
            "  Batch   950  of  1,168.\n",
            "  Batch 1,000  of  1,168.\n",
            "  Batch 1,050  of  1,168.\n",
            "  Batch 1,100  of  1,168.\n",
            "  Batch 1,150  of  1,168.\n",
            "\n",
            "Training Loss: 0.681\n",
            "Validation Loss: 0.798\n",
            "\n",
            " Epoch 3 / 3\n",
            "  Batch    50  of  3,502.\n",
            "  Batch   100  of  3,502.\n",
            "  Batch   150  of  3,502.\n",
            "  Batch   200  of  3,502.\n",
            "  Batch   250  of  3,502.\n",
            "  Batch   300  of  3,502.\n",
            "  Batch   350  of  3,502.\n",
            "  Batch   400  of  3,502.\n",
            "  Batch   450  of  3,502.\n",
            "  Batch   500  of  3,502.\n",
            "  Batch   550  of  3,502.\n",
            "  Batch   600  of  3,502.\n",
            "  Batch   650  of  3,502.\n",
            "  Batch   700  of  3,502.\n",
            "  Batch   750  of  3,502.\n",
            "  Batch   800  of  3,502.\n",
            "  Batch   850  of  3,502.\n",
            "  Batch   900  of  3,502.\n",
            "  Batch   950  of  3,502.\n",
            "  Batch 1,000  of  3,502.\n",
            "  Batch 1,050  of  3,502.\n",
            "  Batch 1,100  of  3,502.\n",
            "  Batch 1,150  of  3,502.\n",
            "  Batch 1,200  of  3,502.\n",
            "  Batch 1,250  of  3,502.\n",
            "  Batch 1,300  of  3,502.\n",
            "  Batch 1,350  of  3,502.\n",
            "  Batch 1,400  of  3,502.\n",
            "  Batch 1,450  of  3,502.\n",
            "  Batch 1,500  of  3,502.\n",
            "  Batch 1,550  of  3,502.\n",
            "  Batch 1,600  of  3,502.\n",
            "  Batch 1,650  of  3,502.\n",
            "  Batch 1,700  of  3,502.\n",
            "  Batch 1,750  of  3,502.\n",
            "  Batch 1,800  of  3,502.\n",
            "  Batch 1,850  of  3,502.\n",
            "  Batch 1,900  of  3,502.\n",
            "  Batch 1,950  of  3,502.\n",
            "  Batch 2,000  of  3,502.\n",
            "  Batch 2,050  of  3,502.\n",
            "  Batch 2,100  of  3,502.\n",
            "  Batch 2,150  of  3,502.\n",
            "  Batch 2,200  of  3,502.\n",
            "  Batch 2,250  of  3,502.\n",
            "  Batch 2,300  of  3,502.\n",
            "  Batch 2,350  of  3,502.\n",
            "  Batch 2,400  of  3,502.\n",
            "  Batch 2,450  of  3,502.\n",
            "  Batch 2,500  of  3,502.\n",
            "  Batch 2,550  of  3,502.\n",
            "  Batch 2,600  of  3,502.\n",
            "  Batch 2,650  of  3,502.\n",
            "  Batch 2,700  of  3,502.\n",
            "  Batch 2,750  of  3,502.\n",
            "  Batch 2,800  of  3,502.\n",
            "  Batch 2,850  of  3,502.\n",
            "  Batch 2,900  of  3,502.\n",
            "  Batch 2,950  of  3,502.\n",
            "  Batch 3,000  of  3,502.\n",
            "  Batch 3,050  of  3,502.\n",
            "  Batch 3,100  of  3,502.\n",
            "  Batch 3,150  of  3,502.\n",
            "  Batch 3,200  of  3,502.\n",
            "  Batch 3,250  of  3,502.\n",
            "  Batch 3,300  of  3,502.\n",
            "  Batch 3,350  of  3,502.\n",
            "  Batch 3,400  of  3,502.\n",
            "  Batch 3,450  of  3,502.\n",
            "  Batch 3,500  of  3,502.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of  1,168.\n",
            "  Batch   100  of  1,168.\n",
            "  Batch   150  of  1,168.\n",
            "  Batch   200  of  1,168.\n",
            "  Batch   250  of  1,168.\n",
            "  Batch   300  of  1,168.\n",
            "  Batch   350  of  1,168.\n",
            "  Batch   400  of  1,168.\n",
            "  Batch   450  of  1,168.\n",
            "  Batch   500  of  1,168.\n",
            "  Batch   550  of  1,168.\n",
            "  Batch   600  of  1,168.\n",
            "  Batch   650  of  1,168.\n",
            "  Batch   700  of  1,168.\n",
            "  Batch   750  of  1,168.\n",
            "  Batch   800  of  1,168.\n",
            "  Batch   850  of  1,168.\n",
            "  Batch   900  of  1,168.\n",
            "  Batch   950  of  1,168.\n",
            "  Batch 1,000  of  1,168.\n",
            "  Batch 1,050  of  1,168.\n",
            "  Batch 1,100  of  1,168.\n",
            "  Batch 1,150  of  1,168.\n",
            "\n",
            "Training Loss: 0.760\n",
            "Validation Loss: 0.754\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.43      0.48      2573\n",
            "           1       0.51      0.62      0.56      2432\n",
            "\n",
            "    accuracy                           0.52      5005\n",
            "   macro avg       0.53      0.53      0.52      5005\n",
            "weighted avg       0.53      0.52      0.52      5005\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 3\n",
            "  Batch    50  of  4,377.\n",
            "  Batch   100  of  4,377.\n",
            "  Batch   150  of  4,377.\n",
            "  Batch   200  of  4,377.\n",
            "  Batch   250  of  4,377.\n",
            "  Batch   300  of  4,377.\n",
            "  Batch   350  of  4,377.\n",
            "  Batch   400  of  4,377.\n",
            "  Batch   450  of  4,377.\n",
            "  Batch   500  of  4,377.\n",
            "  Batch   550  of  4,377.\n",
            "  Batch   600  of  4,377.\n",
            "  Batch   650  of  4,377.\n",
            "  Batch   700  of  4,377.\n",
            "  Batch   750  of  4,377.\n",
            "  Batch   800  of  4,377.\n",
            "  Batch   850  of  4,377.\n",
            "  Batch   900  of  4,377.\n",
            "  Batch   950  of  4,377.\n",
            "  Batch 1,000  of  4,377.\n",
            "  Batch 1,050  of  4,377.\n",
            "  Batch 1,100  of  4,377.\n",
            "  Batch 1,150  of  4,377.\n",
            "  Batch 1,200  of  4,377.\n",
            "  Batch 1,250  of  4,377.\n",
            "  Batch 1,300  of  4,377.\n",
            "  Batch 1,350  of  4,377.\n",
            "  Batch 1,400  of  4,377.\n",
            "  Batch 1,450  of  4,377.\n",
            "  Batch 1,500  of  4,377.\n",
            "  Batch 1,550  of  4,377.\n",
            "  Batch 1,600  of  4,377.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-7089fe85421a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n Epoch {:} / {:}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m       \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_valid_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-3236a6e339dd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mmax_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mnorm_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mmax_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mnorm_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mparameters\u001b[0;34m(self, recurse)\u001b[0m\n\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \"\"\"\n\u001b[0;32m-> 1535\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_parameters\u001b[0;34m(self, prefix, recurse)\u001b[0m\n\u001b[1;32m   1559\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1560\u001b[0m             prefix=prefix, recurse=recurse)\n\u001b[0;32m-> 1561\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1562\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_named_members\u001b[0;34m(self, get_members_fn, prefix, recurse)\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m             \u001b[0mmembers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   1704\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1706\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1707\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3,27,3):\n",
        "  train_text_cov=df1.loc[:int(0.0416*i*0.6*df1.shape[0]),'data'].values\n",
        "  train_labels_cov=df1.loc[:int(0.0416*i*0.6*df1.shape[0]),'label'].values\n",
        "  val_text_cov=df1.loc[int(0.0416*i*0.6*df1.shape[0]):int(0.0416*i*0.8*df1.shape[0]),'data'].values\n",
        "  val_labels_cov=df1.loc[int(0.0416*i*0.6*df1.shape[0]):int(0.0416*i*0.8*df1.shape[0]),\"label\"].values\n",
        "  test_text_cov=df2.loc[int(0.0416*i*0.8*df2.shape[0]):,'data'].values\n",
        "  test_labels_cov=df2.loc[int(0.0416*i*0.8*df2.shape[0]):,'label'].values\n",
        "  max_seq_len = 5\n",
        "  tokens_train = tokenizer.batch_encode_plus(\n",
        "      train_text_cov.tolist(),\n",
        "      max_length = max_seq_len,\n",
        "      pad_to_max_length=True,\n",
        "      truncation=True,\n",
        "      return_token_type_ids=False\n",
        "  )\n",
        "  tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text_cov.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "  tokens_test = tokenizer.batch_encode_plus(\n",
        "      test_text_cov.tolist(),\n",
        "      max_length = max_seq_len,\n",
        "      pad_to_max_length=True,\n",
        "      truncation=True,\n",
        "      return_token_type_ids=False\n",
        "  )\n",
        "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "  train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "  train_y = torch.tensor(train_labels_cov.tolist())\n",
        "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "  val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "  val_y = torch.tensor(val_labels_cov.tolist())\n",
        "  test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "  test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "  test_y = torch.tensor(test_labels_cov.tolist())\n",
        "  batch_size = 1\n",
        "  train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "  val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "  val_sampler = SequentialSampler(val_data)\n",
        "  val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
        "  best_valid_loss = float('inf')\n",
        "  train_losses=[]\n",
        "  valid_losses=[]\n",
        "  epochs=3\n",
        "  for epoch in range(epochs):\n",
        "      print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "      train_loss, _ = train()\n",
        "      valid_loss, _ = evaluate()\n",
        "      if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model3.state_dict(), 'saved_weights3.pt')\n",
        "      train_losses.append(train_loss)\n",
        "      valid_losses.append(valid_loss)\n",
        "      print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "      print(f'Validation Loss: {valid_loss:.3f}')\n",
        "  path = 'saved_weights3.pt'\n",
        "  model3.load_state_dict(torch.load(path))\n",
        "  with torch.no_grad():\n",
        "    preds = model3(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "  preds = np.argmax(preds, axis = 1)\n",
        "  test_y = torch.tensor(test_labels_cov.tolist())\n",
        "  print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "id": "dBFdyZmxNImP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(4,28,4):\n",
        "  train_text_cov=df1.loc[:int(0.0416*i*0.6*df1.shape[0]),'data'].values\n",
        "  train_labels_cov=df1.loc[:int(0.0416*i*0.6*df1.shape[0]),'label'].values\n",
        "  val_text_cov=df1.loc[int(0.0416*i*0.6*df1.shape[0]):int(0.0416*i*0.8*df1.shape[0]),'data'].values\n",
        "  val_labels_cov=df1.loc[int(0.0416*i*0.6*df1.shape[0]):int(0.0416*i*0.8*df1.shape[0]),\"label\"].values\n",
        "  test_text_cov=df2.loc[int(0.0416*i*0.8*df2.shape[0]):,'data'].values\n",
        "  test_labels_cov=df2.loc[int(0.0416*i*0.8*df2.shape[0]):,'label'].values\n",
        "  max_seq_len = 5\n",
        "  tokens_train = tokenizer.batch_encode_plus(\n",
        "      train_text_cov.tolist(),\n",
        "      max_length = max_seq_len,\n",
        "      pad_to_max_length=True,\n",
        "      truncation=True,\n",
        "      return_token_type_ids=False\n",
        "  )\n",
        "  tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text_cov.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "  tokens_test = tokenizer.batch_encode_plus(\n",
        "      test_text_cov.tolist(),\n",
        "      max_length = max_seq_len,\n",
        "      pad_to_max_length=True,\n",
        "      truncation=True,\n",
        "      return_token_type_ids=False\n",
        "  )\n",
        "  train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "  train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "  train_y = torch.tensor(train_labels_cov.tolist())\n",
        "  val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "  val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "  val_y = torch.tensor(val_labels_cov.tolist())\n",
        "  test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "  test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "  test_y = torch.tensor(test_labels_cov.tolist())\n",
        "  batch_size = 1\n",
        "  train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "  val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "  val_sampler = SequentialSampler(val_data)\n",
        "  val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
        "  best_valid_loss = float('inf')\n",
        "  train_losses=[]\n",
        "  valid_losses=[]\n",
        "  epochs=3\n",
        "  for epoch in range(epochs):\n",
        "      print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "      train_loss, _ = train()\n",
        "      valid_loss, _ = evaluate()\n",
        "      if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model4.state_dict(), 'saved_weights4.pt')\n",
        "      train_losses.append(train_loss)\n",
        "      valid_losses.append(valid_loss)\n",
        "      print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "      print(f'Validation Loss: {valid_loss:.3f}')\n",
        "  path = 'saved_weights4.pt'\n",
        "  model4.load_state_dict(torch.load(path))\n",
        "  with torch.no_grad():\n",
        "    preds = model4(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "  preds = np.argmax(preds, axis = 1)\n",
        "  test_y = torch.tensor(test_labels_cov.tolist())\n",
        "  print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "id": "uRPdYEhwNJVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ku0iwLxs58Lf"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CT_BERT",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "377a385f0a4f48468d3efd076632488a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_607837d06af8491ba41c95bebada7f3e",
              "IPY_MODEL_ce3dbb3d27e04a368e9b77f500e2fbff",
              "IPY_MODEL_a516e2e76bf14b6f9b3e6cd29ebc4bf8"
            ],
            "layout": "IPY_MODEL_d3b8bcb5955d4668b562f632798e2c4e"
          }
        },
        "607837d06af8491ba41c95bebada7f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f3096314e154489ad10e6a7af99dd9b",
            "placeholder": "​",
            "style": "IPY_MODEL_3be3275f031b44048f8ab7683f4daf58",
            "value": "Downloading: 100%"
          }
        },
        "ce3dbb3d27e04a368e9b77f500e2fbff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd2ed81f628c48a0b9f576c2010478cf",
            "max": 421,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8e1d58c21c44c4684ffc4bf07d461c1",
            "value": 421
          }
        },
        "a516e2e76bf14b6f9b3e6cd29ebc4bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a83599918bd46b9b08cd8378f8d747e",
            "placeholder": "​",
            "style": "IPY_MODEL_b85c25eaa74249e9abc59a5f1545b70d",
            "value": " 421/421 [00:00&lt;00:00, 11.2kB/s]"
          }
        },
        "d3b8bcb5955d4668b562f632798e2c4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f3096314e154489ad10e6a7af99dd9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3be3275f031b44048f8ab7683f4daf58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd2ed81f628c48a0b9f576c2010478cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8e1d58c21c44c4684ffc4bf07d461c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a83599918bd46b9b08cd8378f8d747e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b85c25eaa74249e9abc59a5f1545b70d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff45c1862d1745e592337fcca7b5f7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f734704293e4742815b65bf71b7738b",
              "IPY_MODEL_555c697177934416846db6e6a91bbac9",
              "IPY_MODEL_be8749eda975498784ab51e0c3105c1b"
            ],
            "layout": "IPY_MODEL_87de31a2e79e48868aadb61328321ed1"
          }
        },
        "9f734704293e4742815b65bf71b7738b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ab33c44b5874479b3f3e3035ad564a9",
            "placeholder": "​",
            "style": "IPY_MODEL_17a695e410294d50b6ade6786deaa3a0",
            "value": "Downloading: 100%"
          }
        },
        "555c697177934416846db6e6a91bbac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4d3fa2144584275b8c460d7d38ee968",
            "max": 1345000672,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d95e5edb01664c08890640e566d736b9",
            "value": 1345000672
          }
        },
        "be8749eda975498784ab51e0c3105c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d91a324b339844b58f40ef82ec33a2b1",
            "placeholder": "​",
            "style": "IPY_MODEL_7c013418de0d46eab81d70c4494d0063",
            "value": " 1.25G/1.25G [01:27&lt;00:00, 17.7MB/s]"
          }
        },
        "87de31a2e79e48868aadb61328321ed1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ab33c44b5874479b3f3e3035ad564a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a695e410294d50b6ade6786deaa3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4d3fa2144584275b8c460d7d38ee968": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d95e5edb01664c08890640e566d736b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d91a324b339844b58f40ef82ec33a2b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c013418de0d46eab81d70c4494d0063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf307d91be384de2bdc9cabe8e933360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26ee9c4c1e7c42ee979603241fc84177",
              "IPY_MODEL_6bf4279923fb4da28e27709a0a9dfe90",
              "IPY_MODEL_4f8237bbfc9d4999bc10c9ca5c0395f9"
            ],
            "layout": "IPY_MODEL_7dc78ecc1502408fbafdac5be8d90cdf"
          }
        },
        "26ee9c4c1e7c42ee979603241fc84177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e03132cdaa30424aa884d3d8078a6e8d",
            "placeholder": "​",
            "style": "IPY_MODEL_5fe5fa64a07346c08d544ea62f169e48",
            "value": "Downloading: 100%"
          }
        },
        "6bf4279923fb4da28e27709a0a9dfe90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd1cbfdc2bea4a84af73cab950cde7ff",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9982cdb421594ca7ae7454726b2a6565",
            "value": 231508
          }
        },
        "4f8237bbfc9d4999bc10c9ca5c0395f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbb7907e95264c48bc5e2f6d11667f50",
            "placeholder": "​",
            "style": "IPY_MODEL_ca7c04ce17fe431d8d8de5681edf0e80",
            "value": " 226k/226k [00:00&lt;00:00, 278kB/s]"
          }
        },
        "7dc78ecc1502408fbafdac5be8d90cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e03132cdaa30424aa884d3d8078a6e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fe5fa64a07346c08d544ea62f169e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd1cbfdc2bea4a84af73cab950cde7ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9982cdb421594ca7ae7454726b2a6565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbb7907e95264c48bc5e2f6d11667f50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7c04ce17fe431d8d8de5681edf0e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}